\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Implementing Gated Recurrent Units On Field-Programmable Gate Array For Brain-Computer Interface Applications}

\author{
    \IEEEauthorblockN{1\textsuperscript{st} Aleksander Berezowski}
    \IEEEauthorblockA{\textit{Schulich School of Engineering} \\
    \textit{University of Calgary}\\
    Calgary, Canada \\
    aleksander.berezowsk@ucalgary.ca}
\and
    \IEEEauthorblockN{2\textsuperscript{nd} Dr. Eli Kinney-Lang}
    \IEEEauthorblockA{\textit{Schulich School of Engineering} \\
    \textit{University of Calgary}\\
    Calgary, Canada \\
    eli.kinneylang@ucalgary.ca}
\and
    \IEEEauthorblockN{2\textsuperscript{nd} Dr. Denis Onen}
    \IEEEauthorblockA{\textit{Schulich School of Engineering} \\
    \textit{University of Calgary}\\
    Calgary, Canada \\
    donen@ucalgary.ca}
}

\maketitle

\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}

\end{IEEEkeywords}

\section{Introduction}

Brain-Computer Interfaces (BCIs) enable communication between the human brain and external devices by processing neural 
signals through machine learning algorithms. These systems follow a structured pipeline encompassing signal acquisition, 
preprocessing, feature extraction, classification, and device control [1]. Due to the temporal and sequential nature of 
brain signals, machine learning algorithms capable of capturing dependencies over time are required. Gated Recurrent 
Units (GRUs) offer a computationally efficient solution for modeling these time-series signals, achieving performance 
comparable to commonly used Long Short-Term Memory (LSTM) networks while requiring significantly fewer computational 
resources due to their simplified architecture [7,9].

The deployment platform for BCI systems critically impacts their practical viability, particularly for real-time, 
low-power applications. Field-Programmable Gate Arrays (FPGAs) provide significant advantages over traditional Central 
Processing Unit (CPU) and Graphics Processing Unit (GPU) implementations due to their reconfigurable hardware, high 
parallelism, and superior power efficiency [12-14]. Despite these benefits, the first hardware implementation of a GRU 
was not presented until 2021 by Zaghloul et al. [11].

This research explores how fundamental design parameters affect the trade-offs between resource utilization, inference 
speed, power consumption, and accuracy in FPGA-based GRU implementations for BCI applications. Specifically, we 
investigate the following research question: "How does input size, hidden state size, and word size
affect resource usage, inference time, power consumption, and accuracy of brain-computer 
interface gated recurrent unit machine learning models deployed on field-programmable gate arrays?"

The primary objective of this research is to systematically characterize how different design parameters affect the 
performance metrics of hardware-implemented GRUs. By quantifying the trade-offs between competing design goals, this 
work aims to provide actionable guidance for designing optimal FPGA-based GRUs for BCI systems. Understanding the 
relationships between parameters is crucial for determining the best GRU design for specific application 
constraints.


\section{Background and Related Work}

\subsection{Gated Recurrent Units for BCI Applications}

EEG signals used in BCI are often lengthy, one-dimensional, complicated, and nonlinear time sequence signals. Due to 
these signal characteristics, Recurrent Neural Networks (RNNs) are commonly used to model this data. However, simple 
RNNs suffer from vanishing and exploding gradient problems, making them struggle to learn long-term dependencies [5]. 
To address this, Hochreiter et al. proposed Long Short-Term Memory (LSTM) units, which use gates to selectively retain, 
update, and output information [6].

GRUs, proposed by Cho et al., are a type of hidden unit similar to LSTM units but 
computationally simpler and more efficient. GRUs use only two gates, compared to LSTMs using four gates, to control 
information flow through the hidden state allowing them to capture dependencies over multiple time scales [7]. 
Chung et al. demonstrated that GRUs and LSTMs achieve comparable performance on multiple datasets [9]. Rivas et 
al. found GRU's and LSTM's performance comparable over several evaluation metrics including Root Mean Square Error (RMSE), 
Mean Square Error (MSE), and Mean Average Error (MAE) [25].

In modern implementations, GRUs are calculated using Equations~\eqref{eq:reset_gate}--\eqref{eq:hidden_state} [30-31].

\begin{align}
r_t &= \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{t-1} + b_{hr}) \label{eq:reset_gate} \\
n_t &= \tanh(W_{in} x_t + b_{in} + r_t \odot (W_{hn} h_{t-1} + b_{hn})) \label{eq:candidate} \\
z_t &= \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{t-1} + b_{hz}) \label{eq:update_gate} \\
h_t &= (1-z_t) \odot n_t + z_t \odot h_{t-1} \label{eq:hidden_state}
\end{align}

$r_t$ (defined by Equation~\eqref{eq:reset_gate}) is the reset gate, $n_t$ (defined by Equation~\eqref{eq:candidate}) 
is the candidate hidden state, $z_t$ (defined by Equation~\eqref{eq:update_gate}) is the update gate, and $h_t$ (defined 
by Equation~\eqref{eq:hidden_state}) is the final hidden state. The variables are defined as follows: $d$ is the input 
feature dimension, $h$ is the number of hidden units, $x_t \in \mathbb{R}^d$ is the input vector at timestep $t$, 
$h_{t-1} \in \mathbb{R}^h$ is the previous hidden state, $W_{ir}, W_{iz}, W_{in} \in \mathbb{R}^{h \times d}$ are 
input-to-hidden weight matrices, $W_{hr}, W_{hz}, W_{hn} \in \mathbb{R}^{h \times h}$ are hidden-to-hidden weight 
matrices, $b_{ir}, b_{iz}, b_{in}, b_{hr}, b_{hz}, b_{hn} \in \mathbb{R}^h$ are bias vectors, $\sigma$ denotes the 
sigmoid activation function, $\tanh$ denotes the hyperbolic tangent function, and $\odot$ denotes the Hadamard (element-wise) 
product.

\subsection{FPGA-Based Neural Network Implementations}

FPGAs are well-suited for BCI systems because their reconfigurability allows for flexible deployment and updating of 
different BCI machine learning models, while their high performance and low power consumption make them ideal for edge 
deployment close to users [12-14]. In 2021, Cai et al. implemented an epilepsy detection algorithm on an FPGA, 
demonstrating that FPGA-based BCI systems tend to have higher accuracy than software-based implementations while 
achieving improved classification performance and reduced power consumption [18].

As shown by Zaghoul et al., the GRU hardware implementation used 50\% fewer Buffers, 42\% fewer Digital Signal Processors 
(DSPs), 39\% less Block RAM (BRAM), and 35\% fewer Slice Look-Up Tables (LUTs) compared to an LSTM implementation [11]. 
Additionally, the GRU had higher inference performance per Watt and lower execution time [11]. This implementation was later 
refined by Rizwan et al. in 2025 [33].

The hardware implementation architecture consists of two primary modules: the gate module and the output module. The 
gate module implements the reset gate, update gate, and activation functions using two Multiply-and-Accumulate (MAC) 
units that are summed and passed through sigmoid or tanh activation functions. The output module performs Hadamard 
products and summation to generate the final hidden state [11].


\section{Methodology}

\subsection{Experimental Design}

The experimental system comprises several interconnected Python modules and a Tcl script that automate the entire 
design, implementation, and analysis pipeline. This automated framework enables systematic exploration of the GRU 
design space by programmatically generating hardware descriptions, orchestrating FPGA toolchain execution, and 
extracting performance metrics.

Python scripts automatically generate SystemVerilog code for the GRU module, top-level wrapper, and a testbench based on 
specified parameters. A Tcl script orchestrates the Xilinx Vivado tool to perform simulation, synthesis, optimization, 
placement, and routing while generating detailed reports. Additional Python scripts parse Vivado-generated reports and 
simulation outputs to extract hardware metrics and calculate the accuracy measurements Mean Absolute Error (MAE) and 
Root Mean Squared Error (RMSE).


\subsection{Design Space and Variables}

Independent Variables
\begin{itemize}
 
\item INT\_WIDTH: Number of integer bits in fixed-point representation, determining the range of 
representable values. The test data ranges from -3.28 to 2.96, requiring a minimum INT\_WIDTH of 3 bits based on two's 
complement representation range of $-2^{\text{INT\_WIDTH}-1}$ to $2^{\text{INT\_WIDTH}-1}-1$. This study uses 
INT\_WIDTH = 6 to provide sufficient headroom and prevent overflow during intermediate calculations.

\item FRAC\_WIDTH: Number of fractional bits in fixed-point representation, determining numerical precision. Lower values 
reduce hardware size but increase quantization error. The tested range is \(FRAC\_WIDTH  \in \{4, 9, 14, 19, 24\}\), 
representing a spectrum from coarse precision to floating-point precision [X].

\item d (Input Dimension): Input feature dimension corresponding to the number of EEG channels in BCI applications. The 
dataset used contains 64 channels, thus 64 will be the upper range for $d$ [46]. Ã–zkahraman et al. demonstrated an 83\% 
accuracy using Motor Imagery with just 6 channels, thus 6 will be the lower range for $d$ [47]. The tested range is 
\(d \in \{4, 8, 16, 32, 64\}\).


\item h (Hidden State Size): Hidden state dimension, a hyperparameter typically determined during GRU training. During GRU 
training it was found that the lower range for h was 4, and the upper range was 16. The tested range is 
\(h \in \{4, 6, 8, 12, 16\}\).
\end{itemize}

Dependent Variables
\begin{itemize}
\item Resource Utilization Metrics: Quantity of Lookup Tables (LUTs), flip-flops (registers), Block RAMs (BRAMs), 
and DSPs (Digital Signal Processors) used.These metrics are extracted from detailed reports output by Vivado.

\item Timing Metrics: Worst Negative Slack (WNS) measures timing margin relative to the 100 MHz clock constraint (10ns 
period). Time utilization is calculated as (10ns - WNS) / 10ns, representing the fraction of the clock period utilized.

\item Power Metrics: Total power (W) represents complete FPGA power consumption. Dynamic power (W) measures power from 
switching activity. Static power (W) quantifies leakage current. All power metrics are extracted from Vivado's power 
analysis reports.

\item Accuracy Metrics: MAE and RMSE quantifies prediction accuracy relative to the ground truth. MAE provides a robust 
error metric less sensitive to outliers than RMSE, however RMSE does a better job quantifying sensitivity to outliers [27].
\end{itemize}

Controlled Variables
\begin{itemize}
\item Target FPGA: Fixed to Xilinx Artix-7 XXX, ensuring consistent LUT architecture, slice organization, and 
resource availability across all trials, as this can affect the outputted design [48].

\item Clock Frequency: Fixed to 100 MHz, providing a consistent performance target.

\item Vivado Version: Fixed to 2024.1, as CAD tool versions can affect synthesis and implementation results [48].

\item Synthesis Settings: Identical optimization flags and strategies applied across all designs.

\item Test Vectors: The same data is used for each testbench, providing 100 reproducible test cases without random 
variation.

\item Weight Values: Identical pre-initialized weight matrices used across all configurations, ensuring that performance 
differences result from architectural parameters rather than weight variation.

\item Generation Scripts: SystemVerilog generation logic remains constant across all parameter combinations, varying only 
the parametric inputs.
\end{itemize}


\subsection{Trial Execution Flow}

Each experimental trial follows a structured sequence to ensure consistency:
\begin{enumerate}
\item RTL Generation: An untested combination of INT\_WIDTH, FRAC\_WIDTH, $d$, and $h$ is 
selected from the design space and used as input parameters for RTL generation. Three SystemVerilog modules are 
automatically generated: the GRU module implementing Equations~\eqref{eq:reset_gate}--\eqref{eq:hidden_state}, 
a wrapper module that instantiates the GRU with synthesis preservation directives to prevent logic optimization, 
and a testbench with 100 deterministic test vectors using a BCI motor imagery dataset for reproducible accuracy 
evaluation.

\item Vivado Execution: A Vivado project is created and all generated SystemVerilog 
files are added to it. Synthesis is executed with resource and timing optimizations, placement and routing is performed, 
and detailed reports on resource utilization, timing analysis, and power consumption are generated. Finally, a simulation 
is run using the generated testbench to produce a simulated output.

\item Data Capture: The detailed reports are parsed to extract hardware metrics including LUTs, registers, BRAMs, DSPs, 
WNS, and power consumption. 

\item Accuracy Calculation: Each simulated output is compared to a ground truth calculated using floating point numbers 
using MAE and MSE to determine GRU implementation accuracy.

\end{enumerate}

This structured flow ensures that each trial is executed identically and carryover effects are eliminated through complete 
regeneration of all files.



\section{Results and Analysis}

GRU implementations were synthesized for the XCU250-FIGD2104-2L-E FPGA. This particular FPGA was selected solely to ensure sufficient 
resources for all design variations under investigation, thereby preventing resource constraints from limiting the scope of experimental 
results. The choice of this specific device does not constrain the applicability of findings; the architectural optimizations and 
performance characteristics demonstrated herein are device-agnostic and can be applied to any FPGA platform. In practical deployments, the 
target FPGA should be selected based on the resource requirements of the optimized design rather than constraining the design to fit a 
predetermined device.

Design Space Exploration Results
Parameter Correlation Analysis
Accuracy vs. Resource Trade-offs
Performance Comparisons


\section{Discussion}

Interpretation of findings
Design guidelines for FPGA-based GRU implementations
Practical implications for BCI systems


\section{Conclusion and Future Work}

Summary of contributions
Shift-and-add multiplication investigation
Real-world validation plans



\section{References}
\renewcommand{\refname}{}
\bibliographystyle{IEEEtran}
\bibliography{LiteratureReview}

\end{document}
