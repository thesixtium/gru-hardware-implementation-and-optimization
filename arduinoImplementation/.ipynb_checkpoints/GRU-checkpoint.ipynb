{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myimporter\n",
    "from BCI_functions import *  # BCI_functions.ipynb contains some functions we might use multiple times in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_1 shape: (259520, 65)\n"
     ]
    }
   ],
   "source": [
    "# ── Load & filter dataset ────────────────────────────────────────────────────\n",
    "dataset_1 = np.load('1.npy')\n",
    "print('dataset_1 shape:', dataset_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using CPU now.\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "device = 'GPU' if gpus else 'CPU'\n",
    "print(f'We are using {device} now.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted labels\n",
    "removed_label = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for ll in removed_label:\n",
    "    idx = dataset_1[:, -1] != ll\n",
    "    dataset_1 = dataset_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Hyperparameters ──────────────────────────────────────────────────────────\n",
    "n_class        = int(11 - len(removed_label))\n",
    "no_feature     = 64\n",
    "segment_length = 16\n",
    "LR             = 0.001\n",
    "EPOCH          = 101\n",
    "n_hidden       = 64\n",
    "l2             = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After segmentation, the shape of the data: (2440, 1025)\n"
     ]
    }
   ],
   "source": [
    "# ── Segmentation & splitting ─────────────────────────────────────────────────\n",
    "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature,\n",
    "                   time_window=segment_length, moving=(segment_length / 2))\n",
    "print('After segmentation, the shape of the data:', data_seg.shape)\n",
    "\n",
    "no_longfeature   = no_feature * segment_length\n",
    "data_seg_feature = data_seg[:, :no_longfeature]\n",
    "data_seg_label   = data_seg[:, no_longfeature:no_longfeature + 1]\n",
    "\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(\n",
    "    data_seg_feature, data_seg_label, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization, training feature shape: (29280, 64) \n",
      "After normalization, test feature shape: (9760, 64)\n",
      "After reshape, training feature shape: (1830, 16, 64) \n",
      "After reshape, test feature shape: (610, 16, 64)\n"
     ]
    }
   ],
   "source": [
    "# ── Normalisation ─────────────────────────────────────────────────────────────\n",
    "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
    "test_feature_2d  = test_feature.reshape([-1, no_feature])\n",
    "\n",
    "scaler1          = StandardScaler().fit(train_feature_2d)\n",
    "train_fea_norm1  = scaler1.transform(train_feature_2d)\n",
    "test_fea_norm1   = scaler1.transform(test_feature_2d)\n",
    "\n",
    "print('After normalization, training feature shape:', train_fea_norm1.shape,\n",
    "      '\\nAfter normalization, test feature shape:',     test_fea_norm1.shape)\n",
    "\n",
    "# Reshape to 3-D: (samples, time_steps, features)\n",
    "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature]).astype(np.float32)\n",
    "test_fea_norm1  = test_fea_norm1.reshape([-1, segment_length, no_feature]).astype(np.float32)\n",
    "\n",
    "print('After reshape, training feature shape:', train_fea_norm1.shape,\n",
    "      '\\nAfter reshape, test feature shape:',     test_fea_norm1.shape)\n",
    "\n",
    "train_label_flat = train_label.flatten().astype(np.int64)\n",
    "test_label_flat  = test_label.flatten().astype(np.int64)\n",
    "\n",
    "BATCH_size = test_fea_norm1.shape[0]  # mirrors original: use test size as batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── tf.data pipelines ─────────────────────────────────────────────────────────\n",
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((train_fea_norm1, train_label_flat))\n",
    "    .shuffle(buffer_size=1024)\n",
    "    .batch(BATCH_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_fea_norm1, test_label_flat)\n",
    ").batch(BATCH_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_layer_1 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m24,960\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_layer_2 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m24,960\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,050</span> (195.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,050\u001b[0m (195.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,050</span> (195.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,050\u001b[0m (195.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Model definition ──────────────────────────────────────────────────────────\n",
    "def build_gru_model(no_feature, n_hidden, n_class, l2_coeff):\n",
    "    \"\"\"\n",
    "    Equivalent to the PyTorch GRU class:\n",
    "      - 2-layer GRU (stacked)\n",
    "      - Dropout 0.3 after GRU\n",
    "      - Dense output layer\n",
    "    \"\"\"\n",
    "    regularizer = keras.regularizers.l2(l2_coeff)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # Layer 1 GRU – return sequences so layer 2 can see all time-steps\n",
    "        layers.GRU(\n",
    "            units=n_hidden,\n",
    "            return_sequences=True,\n",
    "            kernel_regularizer=regularizer,\n",
    "            recurrent_regularizer=regularizer,\n",
    "            bias_regularizer=regularizer,\n",
    "            name='gru_layer_1'\n",
    "        ),\n",
    "        # Layer 2 GRU – return only last time-step output (mirrors [:, -1, :])\n",
    "        layers.GRU(\n",
    "            units=n_hidden,\n",
    "            return_sequences=False,\n",
    "            kernel_regularizer=regularizer,\n",
    "            recurrent_regularizer=regularizer,\n",
    "            bias_regularizer=regularizer,\n",
    "            name='gru_layer_2'\n",
    "        ),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(n_class, name='output')          # logits; softmax applied in loss\n",
    "    ])\n",
    "\n",
    "    model.build(input_shape=(None, segment_length, no_feature))\n",
    "    return model\n",
    "\n",
    "\n",
    "gru_model = build_gru_model(no_feature, n_hidden, n_class, l2)\n",
    "gru_model.summary()\n",
    "\n",
    "optimizer  = keras.optimizers.Adam(learning_rate=LR)\n",
    "loss_func  = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | train loss: 0.7150  train ACC: 0.5016 | test loss: 0.6889  test ACC: 0.5377 | AUC: 0.5685\n",
      "Epoch: 10 | train loss: 0.4184  train ACC: 0.8344 | test loss: 0.4594  test ACC: 0.8033 | AUC: 0.8722\n",
      "Epoch: 20 | train loss: 0.1810  train ACC: 0.9459 | test loss: 0.2215  test ACC: 0.9230 | AUC: 0.9683\n",
      "Epoch: 30 | train loss: 0.0965  train ACC: 0.9803 | test loss: 0.2111  test ACC: 0.9180 | AUC: 0.9791\n",
      "Epoch: 40 | train loss: 0.0418  train ACC: 0.9918 | test loss: 0.1844  test ACC: 0.9607 | AUC: 0.9824\n",
      "Epoch: 50 | train loss: 0.0572  train ACC: 0.9852 | test loss: 0.1605  test ACC: 0.9557 | AUC: 0.9859\n",
      "Epoch: 60 | train loss: 0.0378  train ACC: 0.9885 | test loss: 0.1745  test ACC: 0.9492 | AUC: 0.9858\n",
      "Epoch: 70 | train loss: 0.1003  train ACC: 0.9672 | test loss: 0.1974  test ACC: 0.9459 | AUC: 0.9857\n",
      "Epoch: 80 | train loss: 0.0174  train ACC: 0.9918 | test loss: 0.1518  test ACC: 0.9541 | AUC: 0.9893\n",
      "Epoch: 90 | train loss: 0.0170  train ACC: 0.9885 | test loss: 0.1856  test ACC: 0.9574 | AUC: 0.9901\n",
      "Epoch: 100 | train loss: 0.0131  train ACC: 0.9918 | test loss: 0.2041  test ACC: 0.9541 | AUC: 0.9901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       308\n",
      "           1       0.95      0.96      0.95       302\n",
      "\n",
      "    accuracy                           0.95       610\n",
      "   macro avg       0.95      0.95      0.95       610\n",
      "weighted avg       0.95      0.95      0.95       610\n",
      "\n",
      "BEST TEST ACC: 0.9606557377049181, AUC: 0.9900984776812591\n",
      "Total Running Time: 24.15 seconds\n"
     ]
    }
   ],
   "source": [
    "# ── Custom training loop ──────────────────────────────────────────────────────\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = gru_model(x, training=True)\n",
    "        loss   = loss_func(y, logits)\n",
    "    grads = tape.gradient(loss, gru_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, gru_model.trainable_variables))\n",
    "    return loss, logits\n",
    "\n",
    "\n",
    "best_acc = []\n",
    "best_auc = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # ── training ──\n",
    "    for step, (train_x, train_y) in enumerate(train_dataset):\n",
    "        loss, train_logits = train_step(train_x, train_y)\n",
    "\n",
    "    # ── evaluation every 10 epochs ──\n",
    "    if epoch % 10 == 0:\n",
    "        # Test inference (no dropout)\n",
    "        test_logits = gru_model(test_fea_norm1, training=False)\n",
    "        test_loss   = loss_func(test_label_flat, test_logits).numpy()\n",
    "\n",
    "        # Softmax probabilities for AUC\n",
    "        pred_score    = tf.nn.softmax(test_logits, axis=1).numpy()\n",
    "        test_y_onehot = one_hot(test_label_flat)          # your helper from BCI_functions\n",
    "        auc_score     = roc_auc_score(test_y_onehot, pred_score)\n",
    "\n",
    "        # Hard predictions\n",
    "        pred_y     = np.argmax(pred_score, axis=1)\n",
    "        pred_train = np.argmax(tf.nn.softmax(train_logits, axis=1).numpy(), axis=1)\n",
    "\n",
    "        test_acc  = accuracy_score(test_label_flat, pred_y)\n",
    "        train_acc = accuracy_score(train_y.numpy(), pred_train)\n",
    "\n",
    "        print(\n",
    "            f'Epoch: {epoch} | train loss: {loss.numpy():.4f}  train ACC: {train_acc:.4f}'\n",
    "            f' | test loss: {test_loss:.4f}  test ACC: {test_acc:.4f} | AUC: {auc_score:.4f}'\n",
    "        )\n",
    "        best_acc.append(test_acc)\n",
    "        best_auc.append(auc_score)\n",
    "\n",
    "running_time = time.perf_counter() - start_time\n",
    "\n",
    "print(classification_report(test_label_flat, pred_y))\n",
    "print(f'BEST TEST ACC: {max(best_acc)}, AUC: {max(best_auc)}')\n",
    "print(f'Total Running Time: {round(running_time, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,960</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ gru_layer_1 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m24,960\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_layer_2 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m24,960\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,050</span> (195.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,050\u001b[0m (195.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,050</span> (195.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,050\u001b[0m (195.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "kernel: (64, 192)\n",
      "recurrent_kernel: (64, 192)\n",
      "bias: (2, 192)\n",
      "kernel: (64, 192)\n",
      "recurrent_kernel: (64, 192)\n",
      "bias: (2, 192)\n",
      "kernel: (64, 2)\n",
      "bias: (2,)\n"
     ]
    }
   ],
   "source": [
    "# ── Model inspection (mirrors the final notebook cells) ──────────────────────\n",
    "print(gru_model.summary())\n",
    "\n",
    "# Print each layer and its weights (equivalent to named_parameters())\n",
    "for layer in gru_model.layers:\n",
    "    for weight in layer.weights:\n",
    "        print(f\"{weight.name}: {weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_name = 'gru_model'  # Will be given .tflite suffix\n",
    "c_model_name = 'gru_model'       # Will be given .h suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ajrbe\\AppData\\Local\\Temp\\tmpbpzcy3c0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ajrbe\\AppData\\Local\\Temp\\tmpbpzcy3c0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\ajrbe\\AppData\\Local\\Temp\\tmpbpzcy3c0'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 16, 64), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1798697846736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697845776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697846160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697845008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697847120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697846544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697847696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1798697847504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83280"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(gru_model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "\n",
    "# Add these two lines to fix the TensorListReserve error\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "  c_str = ''\n",
    "\n",
    "  # Create header guard\n",
    "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "  # Add array length at top of file\n",
    "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "  # Declare C variable\n",
    "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "  hex_array = []\n",
    "  for i, val in enumerate(hex_data) :\n",
    "\n",
    "    # Construct string from hex\n",
    "    hex_str = format(val, '#04x')\n",
    "\n",
    "    # Add formatting so each line stays within 80 characters\n",
    "    if (i + 1) < len(hex_data):\n",
    "      hex_str += ','\n",
    "    if (i + 1) % 12 == 0:\n",
    "      hex_str += '\\n '\n",
    "    hex_array.append(hex_str)\n",
    "\n",
    "  # Add closing brace\n",
    "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "  # Close out header guard\n",
    "  c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "  return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
